{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kannada_Mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sauravsolanki/Kannada_Mnist/blob/main/Kannada_Mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVW1NQ720NJO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3bb792a-86f2-43ec-f315-ab89c20b0ef8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOQuf3BR31Qs"
      },
      "source": [
        "root= \"/content/drive/My Drive/colab_data/data/kannada_mnist/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQELB-Sw24XJ"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "\n",
        "# define model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import os\n",
        "import copy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjos8EGak0Ud"
      },
      "source": [
        "class KannadaMnistDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None,phase = \"train\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.data = pd.read_csv(root + csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.phase = phase\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "            \n",
        "        t = self.data.iloc[idx]\n",
        "        label = int(t[0])\n",
        "        img = t[1:]/255.0\n",
        "        image = np.array(img).reshape(1,28,28)\n",
        "        \n",
        "        if self.phase ==\"train\":\n",
        "            sample = {'image': image, 'label': label}\n",
        "            if self.transform:\n",
        "                sample = self.transform(sample)\n",
        "            \n",
        "        else:\n",
        "            sample = {'image': image, 'id': label}\n",
        "            if self.transform:\n",
        "                sample = self.transform(sample)\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCnpasGu12PU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "01c1ff79-ba61-4521-f2a0-482be7aaca34"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(1014, 512)  # 6*6 from image dimension\n",
        "        self.drop_layer = nn.Dropout(p=0.5)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "        # self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        # x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = self.drop_layer(F.relu(self.fc1(x)))\n",
        "        # x = self.drop_layer(F.relu(self.fc2(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "    \n",
        "model = Net()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=1014, out_features=512, bias=True)\n",
            "  (drop_layer): Dropout(p=0.5, inplace=False)\n",
            "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gUWrkyt12So"
      },
      "source": [
        "def train_model(model,dataloader,dataset_sizes,criterion, optimizer, scheduler, num_epochs=5):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        #print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for sample in dataloader[phase]:\n",
        "                inputs, labels  =sample[\"image\"],sample[\"label\"]\n",
        "                \n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                #print(type(input[0])\n",
        "                # zero the parameter gradients\n",
        "                \n",
        "                optimizer.zero_grad()\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs.float())\n",
        "                    \n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            #if phase == 'train':\n",
        "            #    scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('Epoch:{} {} Loss: {:.4f} Acc: {:.4f}'.format(epoch,phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                #save the model\n",
        "                torch.save({'epoch': num_epochs,\n",
        "                    'model_state_dict': best_model_wts,\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'loss': epoch_loss,\n",
        "                    }, PATH)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJg0h4h412OD"
      },
      "source": [
        "batch_size=32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugw3zr_z12KR"
      },
      "source": [
        "train_dataset = KannadaMnistDataset(csv_file='train.csv',root_dir='',transform=None)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, num_workers=256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flOIf2dN1_nZ"
      },
      "source": [
        "val_dataset = KannadaMnistDataset(csv_file='Dig-MNIST.csv',root_dir='.',transform=None)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size,shuffle=False, num_workers=256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DghXjXVK1_sm"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "PATH=\"./best_model1.pth\"\n",
        "dataset_sizes={\"train\":len(train_dataset),\"val\":len(val_dataset)}\n",
        "dataloader={\"train\":train_dataloader,\"val\":val_dataloader}\n",
        "\n",
        "model = Net()\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eeVJlYz1_wg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1beb462c-c71a-4463-da30-a5be6a505462"
      },
      "source": [
        "train_model(model,dataloader,dataset_sizes,criterion, optimizer, scheduler=None, num_epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:0 train Loss: 0.0739 Acc: 0.9777\n",
            "Epoch:0 val Loss: 1.8441 Acc: 0.6747\n",
            "\n",
            "Epoch:1 train Loss: 0.0548 Acc: 0.9833\n",
            "Epoch:1 val Loss: 1.5548 Acc: 0.7174\n",
            "\n",
            "Epoch:2 train Loss: 0.0417 Acc: 0.9868\n",
            "Epoch:2 val Loss: 2.1069 Acc: 0.6877\n",
            "\n",
            "Epoch:3 train Loss: 0.0359 Acc: 0.9888\n",
            "Epoch:3 val Loss: 1.7755 Acc: 0.7371\n",
            "\n",
            "Epoch:4 train Loss: 0.0289 Acc: 0.9911\n",
            "Epoch:4 val Loss: 1.8567 Acc: 0.7341\n",
            "\n",
            "Epoch:5 train Loss: 0.0235 Acc: 0.9925\n",
            "Epoch:5 val Loss: 2.2506 Acc: 0.7203\n",
            "\n",
            "Epoch:6 train Loss: 0.0212 Acc: 0.9928\n",
            "Epoch:6 val Loss: 1.9103 Acc: 0.7334\n",
            "\n",
            "Epoch:7 train Loss: 0.0178 Acc: 0.9939\n",
            "Epoch:7 val Loss: 2.2230 Acc: 0.7224\n",
            "\n",
            "Epoch:8 train Loss: 0.0166 Acc: 0.9944\n",
            "Epoch:8 val Loss: 2.0427 Acc: 0.7407\n",
            "\n",
            "Epoch:9 train Loss: 0.0151 Acc: 0.9950\n",
            "Epoch:9 val Loss: 2.4515 Acc: 0.7360\n",
            "\n",
            "Epoch:10 train Loss: 0.0123 Acc: 0.9958\n",
            "Epoch:10 val Loss: 2.3257 Acc: 0.7576\n",
            "\n",
            "Epoch:11 train Loss: 0.0116 Acc: 0.9962\n",
            "Epoch:11 val Loss: 2.4876 Acc: 0.7333\n",
            "\n",
            "Epoch:12 train Loss: 0.0110 Acc: 0.9961\n",
            "Epoch:12 val Loss: 2.9589 Acc: 0.7348\n",
            "\n",
            "Epoch:13 train Loss: 0.0111 Acc: 0.9962\n",
            "Epoch:13 val Loss: 2.8539 Acc: 0.7497\n",
            "\n",
            "Epoch:14 train Loss: 0.0100 Acc: 0.9969\n",
            "Epoch:14 val Loss: 2.5237 Acc: 0.7566\n",
            "\n",
            "Epoch:15 train Loss: 0.0090 Acc: 0.9970\n",
            "Epoch:15 val Loss: 3.1511 Acc: 0.7333\n",
            "\n",
            "Epoch:16 train Loss: 0.0086 Acc: 0.9970\n",
            "Epoch:16 val Loss: 2.9240 Acc: 0.7539\n",
            "\n",
            "Epoch:17 train Loss: 0.0077 Acc: 0.9975\n",
            "Epoch:17 val Loss: 3.1721 Acc: 0.7335\n",
            "\n",
            "Epoch:18 train Loss: 0.0075 Acc: 0.9976\n",
            "Epoch:18 val Loss: 3.5194 Acc: 0.7295\n",
            "\n",
            "Epoch:19 train Loss: 0.0068 Acc: 0.9977\n",
            "Epoch:19 val Loss: 3.1303 Acc: 0.7429\n",
            "\n",
            "Epoch:20 train Loss: 0.0062 Acc: 0.9977\n",
            "Epoch:20 val Loss: 3.4081 Acc: 0.7558\n",
            "\n",
            "Epoch:21 train Loss: 0.0075 Acc: 0.9977\n",
            "Epoch:21 val Loss: 3.0111 Acc: 0.7606\n",
            "\n",
            "Epoch:22 train Loss: 0.0078 Acc: 0.9974\n",
            "Epoch:22 val Loss: 3.3476 Acc: 0.7548\n",
            "\n",
            "Epoch:23 train Loss: 0.0057 Acc: 0.9980\n",
            "Epoch:23 val Loss: 3.6781 Acc: 0.7450\n",
            "\n",
            "Epoch:24 train Loss: 0.0059 Acc: 0.9979\n",
            "Epoch:24 val Loss: 3.8972 Acc: 0.7335\n",
            "\n",
            "Epoch:25 train Loss: 0.0056 Acc: 0.9982\n",
            "Epoch:25 val Loss: 3.7956 Acc: 0.7451\n",
            "\n",
            "Epoch:26 train Loss: 0.0054 Acc: 0.9982\n",
            "Epoch:26 val Loss: 3.9268 Acc: 0.7405\n",
            "\n",
            "Epoch:27 train Loss: 0.0055 Acc: 0.9981\n",
            "Epoch:27 val Loss: 4.0085 Acc: 0.7443\n",
            "\n",
            "Epoch:28 train Loss: 0.0044 Acc: 0.9985\n",
            "Epoch:28 val Loss: 4.2482 Acc: 0.7462\n",
            "\n",
            "Epoch:29 train Loss: 0.0047 Acc: 0.9985\n",
            "Epoch:29 val Loss: 4.2656 Acc: 0.7397\n",
            "\n",
            "Epoch:30 train Loss: 0.0052 Acc: 0.9983\n",
            "Epoch:30 val Loss: 3.9254 Acc: 0.7507\n",
            "\n",
            "Epoch:31 train Loss: 0.0044 Acc: 0.9986\n",
            "Epoch:31 val Loss: 4.2018 Acc: 0.7463\n",
            "\n",
            "Epoch:32 train Loss: 0.0046 Acc: 0.9984\n",
            "Epoch:32 val Loss: 4.2889 Acc: 0.7484\n",
            "\n",
            "Epoch:33 train Loss: 0.0047 Acc: 0.9986\n",
            "Epoch:33 val Loss: 4.6783 Acc: 0.7377\n",
            "\n",
            "Epoch:34 train Loss: 0.0049 Acc: 0.9985\n",
            "Epoch:34 val Loss: 4.2814 Acc: 0.7440\n",
            "\n",
            "Epoch:35 train Loss: 0.0053 Acc: 0.9982\n",
            "Epoch:35 val Loss: 4.2513 Acc: 0.7478\n",
            "\n",
            "Epoch:36 train Loss: 0.0045 Acc: 0.9985\n",
            "Epoch:36 val Loss: 4.2030 Acc: 0.7506\n",
            "\n",
            "Epoch:37 train Loss: 0.0041 Acc: 0.9989\n",
            "Epoch:37 val Loss: 4.8531 Acc: 0.7348\n",
            "\n",
            "Epoch:38 train Loss: 0.0039 Acc: 0.9989\n",
            "Epoch:38 val Loss: 4.4990 Acc: 0.7431\n",
            "\n",
            "Epoch:39 train Loss: 0.0045 Acc: 0.9987\n",
            "Epoch:39 val Loss: 4.6994 Acc: 0.7424\n",
            "\n",
            "Epoch:40 train Loss: 0.0039 Acc: 0.9989\n",
            "Epoch:40 val Loss: 4.3881 Acc: 0.7463\n",
            "\n",
            "Epoch:41 train Loss: 0.0046 Acc: 0.9986\n",
            "Epoch:41 val Loss: 5.1703 Acc: 0.7236\n",
            "\n",
            "Epoch:42 train Loss: 0.0033 Acc: 0.9989\n",
            "Epoch:42 val Loss: 4.8284 Acc: 0.7463\n",
            "\n",
            "Epoch:43 train Loss: 0.0036 Acc: 0.9989\n",
            "Epoch:43 val Loss: 4.9790 Acc: 0.7356\n",
            "\n",
            "Epoch:44 train Loss: 0.0037 Acc: 0.9987\n",
            "Epoch:44 val Loss: 4.8973 Acc: 0.7388\n",
            "\n",
            "Epoch:45 train Loss: 0.0043 Acc: 0.9987\n",
            "Epoch:45 val Loss: 4.5827 Acc: 0.7435\n",
            "\n",
            "Epoch:46 train Loss: 0.0035 Acc: 0.9987\n",
            "Epoch:46 val Loss: 5.0022 Acc: 0.7476\n",
            "\n",
            "Epoch:47 train Loss: 0.0038 Acc: 0.9988\n",
            "Epoch:47 val Loss: 4.9234 Acc: 0.7527\n",
            "\n",
            "Epoch:48 train Loss: 0.0042 Acc: 0.9986\n",
            "Epoch:48 val Loss: 4.7491 Acc: 0.7494\n",
            "\n",
            "Epoch:49 train Loss: 0.0036 Acc: 0.9988\n",
            "Epoch:49 val Loss: 5.0363 Acc: 0.7380\n",
            "\n",
            "Epoch:50 train Loss: 0.0032 Acc: 0.9989\n",
            "Epoch:50 val Loss: 5.1421 Acc: 0.7465\n",
            "\n",
            "Epoch:51 train Loss: 0.0028 Acc: 0.9990\n",
            "Epoch:51 val Loss: 5.4483 Acc: 0.7421\n",
            "\n",
            "Epoch:52 train Loss: 0.0035 Acc: 0.9990\n",
            "Epoch:52 val Loss: 5.0114 Acc: 0.7456\n",
            "\n",
            "Epoch:53 train Loss: 0.0036 Acc: 0.9990\n",
            "Epoch:53 val Loss: 5.1288 Acc: 0.7533\n",
            "\n",
            "Epoch:54 train Loss: 0.0024 Acc: 0.9991\n",
            "Epoch:54 val Loss: 5.1019 Acc: 0.7563\n",
            "\n",
            "Epoch:55 train Loss: 0.0033 Acc: 0.9990\n",
            "Epoch:55 val Loss: 4.8903 Acc: 0.7520\n",
            "\n",
            "Epoch:56 train Loss: 0.0032 Acc: 0.9990\n",
            "Epoch:56 val Loss: 5.2243 Acc: 0.7593\n",
            "\n",
            "Epoch:57 train Loss: 0.0030 Acc: 0.9992\n",
            "Epoch:57 val Loss: 5.1797 Acc: 0.7499\n",
            "\n",
            "Epoch:58 train Loss: 0.0037 Acc: 0.9989\n",
            "Epoch:58 val Loss: 5.5952 Acc: 0.7314\n",
            "\n",
            "Epoch:59 train Loss: 0.0024 Acc: 0.9992\n",
            "Epoch:59 val Loss: 6.1644 Acc: 0.7391\n",
            "\n",
            "Epoch:60 train Loss: 0.0031 Acc: 0.9990\n",
            "Epoch:60 val Loss: 5.3628 Acc: 0.7561\n",
            "\n",
            "Epoch:61 train Loss: 0.0028 Acc: 0.9990\n",
            "Epoch:61 val Loss: 6.1848 Acc: 0.7471\n",
            "\n",
            "Epoch:62 train Loss: 0.0030 Acc: 0.9990\n",
            "Epoch:62 val Loss: 5.7606 Acc: 0.7521\n",
            "\n",
            "Epoch:63 train Loss: 0.0037 Acc: 0.9989\n",
            "Epoch:63 val Loss: 5.4020 Acc: 0.7502\n",
            "\n",
            "Epoch:64 train Loss: 0.0023 Acc: 0.9991\n",
            "Epoch:64 val Loss: 5.3983 Acc: 0.7531\n",
            "\n",
            "Epoch:65 train Loss: 0.0031 Acc: 0.9991\n",
            "Epoch:65 val Loss: 5.5797 Acc: 0.7517\n",
            "\n",
            "Epoch:66 train Loss: 0.0036 Acc: 0.9990\n",
            "Epoch:66 val Loss: 5.9426 Acc: 0.7326\n",
            "\n",
            "Epoch:67 train Loss: 0.0021 Acc: 0.9992\n",
            "Epoch:67 val Loss: 5.8595 Acc: 0.7398\n",
            "\n",
            "Epoch:68 train Loss: 0.0027 Acc: 0.9992\n",
            "Epoch:68 val Loss: 5.3819 Acc: 0.7550\n",
            "\n",
            "Epoch:69 train Loss: 0.0033 Acc: 0.9990\n",
            "Epoch:69 val Loss: 5.5858 Acc: 0.7607\n",
            "\n",
            "Epoch:70 train Loss: 0.0030 Acc: 0.9990\n",
            "Epoch:70 val Loss: 5.6617 Acc: 0.7423\n",
            "\n",
            "Epoch:71 train Loss: 0.0023 Acc: 0.9994\n",
            "Epoch:71 val Loss: 5.5888 Acc: 0.7413\n",
            "\n",
            "Epoch:72 train Loss: 0.0026 Acc: 0.9992\n",
            "Epoch:72 val Loss: 5.7194 Acc: 0.7496\n",
            "\n",
            "Epoch:73 train Loss: 0.0028 Acc: 0.9993\n",
            "Epoch:73 val Loss: 5.6623 Acc: 0.7561\n",
            "\n",
            "Epoch:74 train Loss: 0.0026 Acc: 0.9992\n",
            "Epoch:74 val Loss: 6.1722 Acc: 0.7436\n",
            "\n",
            "Epoch:75 train Loss: 0.0023 Acc: 0.9994\n",
            "Epoch:75 val Loss: 5.7597 Acc: 0.7433\n",
            "\n",
            "Epoch:76 train Loss: 0.0027 Acc: 0.9991\n",
            "Epoch:76 val Loss: 6.5653 Acc: 0.7357\n",
            "\n",
            "Epoch:77 train Loss: 0.0024 Acc: 0.9993\n",
            "Epoch:77 val Loss: 6.7544 Acc: 0.7439\n",
            "\n",
            "Epoch:78 train Loss: 0.0036 Acc: 0.9990\n",
            "Epoch:78 val Loss: 6.9269 Acc: 0.7322\n",
            "\n",
            "Epoch:79 train Loss: 0.0024 Acc: 0.9992\n",
            "Epoch:79 val Loss: 5.9485 Acc: 0.7423\n",
            "\n",
            "Epoch:80 train Loss: 0.0032 Acc: 0.9990\n",
            "Epoch:80 val Loss: 6.1921 Acc: 0.7398\n",
            "\n",
            "Epoch:81 train Loss: 0.0020 Acc: 0.9994\n",
            "Epoch:81 val Loss: 7.2853 Acc: 0.7248\n",
            "\n",
            "Epoch:82 train Loss: 0.0026 Acc: 0.9993\n",
            "Epoch:82 val Loss: 6.8105 Acc: 0.7331\n",
            "\n",
            "Epoch:83 train Loss: 0.0022 Acc: 0.9995\n",
            "Epoch:83 val Loss: 6.0850 Acc: 0.7469\n",
            "\n",
            "Epoch:84 train Loss: 0.0032 Acc: 0.9990\n",
            "Epoch:84 val Loss: 6.4681 Acc: 0.7301\n",
            "\n",
            "Epoch:85 train Loss: 0.0027 Acc: 0.9992\n",
            "Epoch:85 val Loss: 6.6512 Acc: 0.7365\n",
            "\n",
            "Epoch:86 train Loss: 0.0024 Acc: 0.9993\n",
            "Epoch:86 val Loss: 6.8025 Acc: 0.7394\n",
            "\n",
            "Epoch:87 train Loss: 0.0034 Acc: 0.9991\n",
            "Epoch:87 val Loss: 6.1083 Acc: 0.7460\n",
            "\n",
            "Epoch:88 train Loss: 0.0024 Acc: 0.9993\n",
            "Epoch:88 val Loss: 5.9790 Acc: 0.7390\n",
            "\n",
            "Epoch:89 train Loss: 0.0029 Acc: 0.9993\n",
            "Epoch:89 val Loss: 6.7681 Acc: 0.7481\n",
            "\n",
            "Epoch:90 train Loss: 0.0022 Acc: 0.9994\n",
            "Epoch:90 val Loss: 6.4328 Acc: 0.7405\n",
            "\n",
            "Epoch:91 train Loss: 0.0030 Acc: 0.9991\n",
            "Epoch:91 val Loss: 6.8589 Acc: 0.7295\n",
            "\n",
            "Epoch:92 train Loss: 0.0024 Acc: 0.9994\n",
            "Epoch:92 val Loss: 6.4116 Acc: 0.7386\n",
            "\n",
            "Epoch:93 train Loss: 0.0017 Acc: 0.9995\n",
            "Epoch:93 val Loss: 7.0301 Acc: 0.7302\n",
            "\n",
            "Epoch:94 train Loss: 0.0023 Acc: 0.9992\n",
            "Epoch:94 val Loss: 6.7935 Acc: 0.7424\n",
            "\n",
            "Epoch:95 train Loss: 0.0019 Acc: 0.9995\n",
            "Epoch:95 val Loss: 6.3959 Acc: 0.7489\n",
            "\n",
            "Epoch:96 train Loss: 0.0025 Acc: 0.9992\n",
            "Epoch:96 val Loss: 6.3759 Acc: 0.7441\n",
            "\n",
            "Epoch:97 train Loss: 0.0027 Acc: 0.9993\n",
            "Epoch:97 val Loss: 6.6604 Acc: 0.7435\n",
            "\n",
            "Epoch:98 train Loss: 0.0017 Acc: 0.9996\n",
            "Epoch:98 val Loss: 7.9939 Acc: 0.7148\n",
            "\n",
            "Epoch:99 train Loss: 0.0027 Acc: 0.9993\n",
            "Epoch:99 val Loss: 7.4960 Acc: 0.7324\n",
            "\n",
            "Training complete in 77m 32s\n",
            "Best val Acc: 0.760742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=1014, out_features=512, bias=True)\n",
              "  (drop_layer): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACqmqSa61_0l"
      },
      "source": [
        "# class wise accuracy\n",
        "# load best model \n",
        "model.load_state_dict(torch.load(PATH)[\"model_state_dict\"])\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "with torch.no_grad():\n",
        "    for sample in val_dataloader:\n",
        "        inputs, labels = sample[\"image\"],sample[\"label\"]\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(inputs.float())\n",
        "        #print(labels.item)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        #print(predicted)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        #print(c)\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "        \n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %d : %2d %%' % (\n",
        "        i, 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FlBKuoQ1_u9"
      },
      "source": [
        "def test_model(dataloader,model):\n",
        "    # load best model weights\n",
        "    #model.load_state_dict(best_model_wts)\n",
        "    since = time.time()\n",
        "    p=\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for sample in dataloader:\n",
        "                inputs, idx  =sample[\"image\"],sample[\"id\"]                \n",
        "                inputs = inputs.to(device)\n",
        "                \n",
        "                outputs = model(inputs.float())\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                #idx,preds\n",
        "                #print(idx,preds)\n",
        "                for i,j in zip(idx,preds):\n",
        "                    p+=str(i.item())+\",\"+str(j.item())+\"\\n\"\n",
        "                     \n",
        "    time_elapsed = time.time() - since\n",
        "    print('Testing complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    return p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvb7Occ3zUDm"
      },
      "source": [
        "test_dataset = KannadaMnistDataset(csv_file='test.csv',\n",
        "                                           root_dir='',\n",
        "                                           transform=None,\n",
        "                                           phase=\"test\")\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=4,shuffle=False, num_workers=0)\n",
        "\n",
        "submit=test_model(test_dataloader,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoNtUgAIzUTT"
      },
      "source": [
        "submitt = \"id,label\\n\"+submit\n",
        "with open(\"submission.csv\",\"w\") as f:\n",
        "    f.write(submitt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_nc07v81_qu"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('submission.csv') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8ajTvT1zm5t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}